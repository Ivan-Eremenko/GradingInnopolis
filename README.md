# GradingInnopolis
A test repository for educational purposes.

# Чат-бот на основе Llama

Это приложение представляет собой чат-бота, использующего модель Llama для генерации ответов на сообщения пользователей. Чат-бот может быть настроен для работы с различными моделями, загружаемыми по URL.

## Установка

1. **Клонируйте репозиторий**:

   ```bash
   git clone <URL_вашего_репозитория>
   cd Chat_bot_gradio_llma_cpp
   ```

2. **Создайте виртуальное окружение** (рекомендуется):

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Для Linux/Mac
   .venv\Scripts\activate  # Для Windows
   ```

3. **Установите зависимости**:

   Убедитесь, что у вас установлен `pip`, затем выполните:

   ```bash
   pip install -r requirements.txt
   ```

## Использование

Для запуска чат-бота выполните следующую команду:

```bash
python main/app.py --model_url`: (необязательный) URL модели в формате GGUF. По умолчанию используется: https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q8_0.gguf
```
### Пример запуска
```bash
python main/app.py --model_url https://example.com/path/to/your/model.gguf
```

После запуска приложение будет доступно по адресу `http://0.0.0.0:7860`.

## Описание

- **Чат-бот**: Использует модель Llama для генерации ответов на сообщения пользователей.
- **Интерфейс**: Приложение использует библиотеку Gradio для создания веб-интерфейса.

## Примечания

- Убедитесь, что у вас есть доступ к интернету для загрузки модели, если она не находится локально.
- Модель должна быть в формате GGUF.
